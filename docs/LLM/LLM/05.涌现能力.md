# LLM的涌现能力

## 7. LLMs中，涌现能力是啥原因

- 什么是“涌现能力”？
    - 当一个复杂系统由很多微小个体构成，这些微小个体凑到一起，相互作用，当数量足够多时，在宏观层面上展现出微观个体无法解释的特殊现象，就可以称之为“涌现现象”。

<center>
    <img src="../fig/05-intro.png">
</center>

- 在日常生活中也有一些涌现现象，比如雪花的形成、堵车、动物迁徙、涡流形成等。
- 这里以雪花为例来解释：雪花的构成是水分子，水分子很小，但是大量的水分子如果在外界温度条件变化的前提下相互作用，在宏观层面就会形成一个很规律、很对称、和美丽的雪花。

### 猜想一：任务的评价指标不够平滑
- 一种猜想是因为很多任务的评价指标不够平滑，导致我们现在看到的涌现现象

<center>
    <img src="../fig/05-example.png">
</center>

- 关于这一点，我们拿 Emoji_Movie 任务来给出解释。Emoji_Movie 任务是说输入 Emoji 图像，要求 LLM 给出完全正确的电影名称，只有一字不错才算正确，错一个单词都算错。

- 如上图所示，输入的 Emoji 是一个女孩的笑脸，后面跟着三张鱼类的图片，您可以猜猜这是什么电影。下面左侧的 2m 代表模型参数规模是 200 万参数，以及对应模型给出的回答。可以看出，随着模型规模不断增大至 128B 时，LLM 才能完全猜对电影名称，但是在模型到了 125m 和 4b 的时候，其实模型已经慢慢开始接近正确答案了。

<center>
    <img src="../fig/05-emoji_movie.png">
</center>

- 如果评价指标要求很严格，要求一字不错才算对，那么 Emoji_movie 任务我们就会看到涌现现象的出现，如上图图左所示。但是，如果我们把问题形式换成多选题，就是给出几个候选答案，让 LLM 选，那么随着模型不断增大，任务效果在持续稳定变好，但涌现现象消失，如上图图右所示。这说明评价指标不够平滑，起码是一部分任务看到涌现现象的原因。

### 猜想二：复杂任务 vs 子任务

- 展现出涌现现象的任务有一个共性，就是任务往往是由多个子任务构成的复杂任务。
- 也就是说，最终任务过于复杂，如果仔细分析，可以看出它由多个子任务构成，这时候，子任务效果往往随着模型增大，符合 Scaling Law，而最终任务则体现为涌现现象。
- 这个其实好理解，比如我们假设某个任务 T 有 5 个子任务 Sub-T 构成，每个 sub-T 随着模型增长，指标从 40% 提升到 60%，但是最终任务的指标只从 1.1% 提升到了 7%，也就是说宏观上看到了涌现现象，但是子任务效果其实是平滑增长的。

<center>
    <img src="../fig/05-tasks.png">
</center>

拿国际象棋任务来作为例子，如上图所示，让语言模型预测下一步，最终评价指标是只有"将死"才算赢。如果按"将死"评估（红线），发现随着模型增大，模型在缓慢上升，符合涌现的表现。若评估 LLM 合法移动（绿线），而在合法的移动步骤里进行正确选择才能最后"将死"是个子任务，所以其实这是比将死简单的一个子任务。我们看合法移动随着模型规模，效果持续上升。此时，我们是看不到涌现现象的。

### 总结

关于涌现能力的猜想，目前主流猜想：

- 任务的评价指标不够平滑；
- 复杂任务 vs 子任务。

> 内容参考来源：张俊林老师《大语言模型的涌现能力：现象与解释》