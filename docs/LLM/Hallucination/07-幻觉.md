# 幻觉介绍

## 一、什么是大模型幻觉问题？

### 1.1 大模型幻觉问题定义

> 一本正经的胡说八道 

- 定义：当模型生成的文本不遵循原文（一致性，Faithfulness）或者不符合事实（事实性，Factualness），我们就可以认为模型出现了幻觉的问题。

### 1.2 何为 Faithfulness(一致性) and Factualness(事实性)?

- Faithfulness：是否遵循input content；  
- Factualness：是否符合世界知识；

### 1.3 传统任务中的模型幻觉 vs LLMs 中模型幻觉

- 在传统任务里，幻觉大都是指的是Faithfulness：  
    - Intrinsic Hallucination（信息冲突）：LMs在生成回复时，与输入信息产生了冲突，例如摘要问题里，abstract和document的信息不一致；  
    - Extrinsic Hallucination（无中生有）：LMs在生成回复时，输出一些并没有体现在输入中的额外信息，比如邮箱地址、电话号码、住址，并且难以验证其真假。  
- 而面向LLMs，我们通常考虑的幻觉则是Factualness：  
    - 因为我们应用LLM的形式是open-domain Chat，而不是局限于特定任务，所以数据源可以看做任意的世界知识。LLMs如果生成了不在input source里的额外信息，但是符合事实的，这种情况也可能是对我们有帮助的。


## 二、为什么会出现大模型幻觉问题？

### 2.1 从数据角度进行分析

在数据构建过程中，由于以下问题，导致模型幻觉的发生：

- 训练数据可信度问题。
    - 由于大模型的训练数据都是通过众包/爬虫检索方式收集得到的，这种数据构建方式的优点是量比较大，但是缺点是包含大量虚假信息。这种虚假信息直接导致的问题就是使模型出现错误认知；
- 重复数据问题。过多的重复信息也可能导致模型的知识记忆出现bias，从而导致幻觉；

### 2.2 从模型角度进行分析

不止是数据角度问题，大模型幻觉问题出现的原因还表现在模型角度。

- **模型结构**：如果是较弱的backbone（比如RNN）可能导致比较严重的幻觉问题，但在LLMs时代应该不太可能存在这一问题；
- **解码算法**：研究表明，如果使用不确定性较高的采样算法（e.g., top-p）会诱导LMs出现更严重的幻觉问题。甚至可以故意在解码算法中加入一些随机性，进一步让LMs胡编乱造（可以用该方法生成一些negative samples）

    > top-p采样（也称为核采样）是一种引入不确定性的采样算法，常用来生成更加多样化和创造性的文本。
    
    > top-p采样的原理是：模型从预测概率最高的词语开始累加，当这些词的概率总和达到一个设定的阈值（p值）后停止，从而在这些候选词中随机选取一个词生成。这种算法能够避免仅生成概率最高的词，进而提升文本的流畅性和丰富度。

- **暴露偏差**：训练和测试阶段不匹配的exposure bias问题可能导致LLMs出现幻觉，特别是生成long-form response的时候。
  
    > 在训练阶段，模型是根据真实的、人工标注的文本片段生成内容。每一步生成时，模型会接收到真实的前文内容作为输入。然而，在实际生成（测试阶段），模型只能依赖自己之前生成的文本，而不再是完全可靠的真实数据。

- **参数知识**：LMs在预测新阶段的错误的知识，将会严重导致幻觉问题。